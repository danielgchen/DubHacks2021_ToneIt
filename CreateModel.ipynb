{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DubHacks2021_ToneIt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFAudkAYZr6M"
      },
      "source": [
        "#Prepare for Model Creation\n",
        "##Download packages\n",
        "There are two versions of SparkNLP that we could utilize (both work) however we vyed for the newer 3.1.2 version of Apache Spark which works with the newest version of Spark NLP (version 3.3.1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fBCoV7JYREQF",
        "outputId": "bc01f377-c8a8-48a3-b8ad-76d59c38e704"
      },
      "source": [
        "import os\n",
        "# > Old Package Versions\n",
        "# # Install java\n",
        "# ! apt-get update -qq\n",
        "# ! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "# ! java -version\n",
        "# # Install pyspark\n",
        "# ! pip install --ignore-installed pyspark==2.4.4\n",
        "# # Install Spark NLP\n",
        "# ! pip install --ignore-installed spark-nlp==2.5.1\n",
        "\n",
        "# > New Package Versions\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 65 kB/s \n",
            "\u001b[K     |████████████████████████████████| 122 kB 52.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 36.3 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08JBKhsdZqF_"
      },
      "source": [
        "## Import the packages\n",
        "Now that we've downloaded the necessary packages we import them and instantiate a spark session. We set the `gpu` parameter to `True` even though this CoLab session doesn't have GPU equipped as we would prefer to use GPU when possible. We then print out the package versions to ensure we have the versions we believe we have installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "q137DmdURQU8",
        "outputId": "feeca798-78a1-4422-ca75-b1f64e534761"
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start(gpu = True) # for GPU training\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.3.1\n",
            "Apache Spark version: 3.1.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://60c26fed91ea:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fcfa1caae10>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0ypzzy1Z6P3"
      },
      "source": [
        "##Get the dataset\n",
        "###Data cleaning\n",
        "This dataset is downloaded from Kaggle, specifically from [this site](www.google.com). We then import it as a json file (some preprocessing has been done via Java) and clean it up a little more to the Spark NLP format. We'll also split the dataset up here by doing a 25% test and 75% train ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEGNITxnZ24Y"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "np.random.seed(0)  # for consistency\n",
        "# open the training and the testing sets\n",
        "with open('trainTone.clean.txt', 'wt') as writer_train:\n",
        "  with open('testTone.clean.txt', 'wt') as writer_test:\n",
        "    # write the headers for both\n",
        "    writer_train.writelines('category,description\\n')\n",
        "    writer_test.writelines('category,description\\n')\n",
        "    # loop through the lines of the full unnormalized trainTone dataset\n",
        "    lines = json.load(open('trainTone.txt'))\n",
        "    for line in lines:\n",
        "      # get the relevant data and construct the line\n",
        "      tone,sentence = line['tone'].title(),line['sentence']\n",
        "      output_line = f'{tone},\"{sentence}\"\\n'\n",
        "      write_to_train = np.random.uniform(0,1) > 0.25\n",
        "      if(write_to_train):\n",
        "        writer_train.writelines(output_line)\n",
        "      else:\n",
        "        writer_test.writelines(output_line)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX0EQzxxaBWY"
      },
      "source": [
        "###Read in the datasets\n",
        "We load the training and testing datasets and show a brief set of lines from each one to ensure data quality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6cn4MqNaEsz",
        "outputId": "36a4cc0e-6960-4bbc-f287-3b237859cbf8"
      },
      "source": [
        "# load the training dataset\n",
        "trainDataset = spark.read.option('header', True).csv('trainTone.clean.txt')\n",
        "trainDataset.show(truncate=50, n=5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------+\n",
            "|category|                                       description|\n",
            "+--------+--------------------------------------------------+\n",
            "| Sadness|                           i didnt feel humiliated|\n",
            "| Sadness|i can go from feeling so hopeless to so damned ...|\n",
            "|   Anger|  im grabbing a minute to post i feel greedy wrong|\n",
            "|    Love|i am ever feeling nostalgic about the fireplace...|\n",
            "|   Anger|                              i am feeling grouchy|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4YwdhjYPQhP",
        "outputId": "c3b69e33-89f9-4649-c4e2-540529d34d69"
      },
      "source": [
        "# load the testing dataset\n",
        "testDataset = spark.read.option('header', True).csv('testTone.clean.txt')\n",
        "testDataset.show(truncate=50, n=5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------+\n",
            "|category|                                       description|\n",
            "+--------+--------------------------------------------------+\n",
            "|     Joy|i have immense sympathy with the general point ...|\n",
            "|     Joy|   i do not feel reassured anxiety is on each side|\n",
            "| Sadness|              i didnt really feel that embarrassed|\n",
            "|   Anger|i already feel like i fucked up though because ...|\n",
            "| Sadness|i feel so inhibited in someone elses kitchen li...|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXIrEUH9aPK2"
      },
      "source": [
        "###Checkout the class distribution\n",
        "Our dataset is multiclass but this doesn't mean there are balanced classes so we should read the classes to see how this may affect our data (less-represented classes may not be predicted as often)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujwwvL01RZRn",
        "outputId": "eaa708e7-b3f8-4e73-b3a1-ef68f0492e53"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "print('Training dataset class distribution...')\n",
        "trainDataset.groupBy('category').count().orderBy(col('count').desc()).show()\n",
        "print('Testing dataset class distribution...')\n",
        "testDataset.groupBy('category').count().orderBy(col('count').desc()).show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset class distribution...\n",
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|     Joy| 3984|\n",
            "| Sadness| 3459|\n",
            "|   Anger| 1629|\n",
            "|    Fear| 1433|\n",
            "|    Love|  976|\n",
            "|Surprise|  418|\n",
            "+--------+-----+\n",
            "\n",
            "Testing dataset class distribution...\n",
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|     Joy| 1378|\n",
            "| Sadness| 1207|\n",
            "|   Anger|  530|\n",
            "|    Fear|  504|\n",
            "|    Love|  328|\n",
            "|Surprise|  154|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JB4vCseaUV5"
      },
      "source": [
        "##Run the model\n",
        "###Build the pipeline\n",
        "We assemble a pipeline that takes the 'document' which are just sentences then vectorizes them via the universal sentence encoder and then classifies these embeddings into categories. We use an example here with a set batch size and set epoch size however these can be varied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EXmCQymR5rB",
        "outputId": "08c31aad-b1b1-4062-f3e8-1a27d7284615"
      },
      "source": [
        "# actual content is inside description column\n",
        "document = DocumentAssembler()\\\n",
        "      .setInputCol(\"description\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "# we can also use sentece detector here if we want to train on and get predictions for each sentence\n",
        "use = UniversalSentenceEncoder.pretrained(\"tfhub_use_lg\", \"en\") \\\n",
        "      .setInputCols(\"document\") \\\n",
        "      .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# the classes/labels/categories are in category column\n",
        "classifierdl = ClassifierDLApproach()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCol(\"class\")\\\n",
        "      .setLabelColumn(\"category\")\\\n",
        "      .setMaxEpochs(50)\\\n",
        "      .setBatchSize(8)\\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setRandomSeed(0)  # for consistency\n",
        "\n",
        "use_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        classifierdl\n",
        "    ])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use_lg download started this may take some time.\n",
            "Approximate size to download 753.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHww7Mw0aakv"
      },
      "source": [
        "###Train the model\n",
        "We also time the model to see how long it takes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E8rwF0JR9-q",
        "outputId": "b6d459e0-b4c5-4755-c972-f2b44e97bccd"
      },
      "source": [
        "%%time\n",
        "clf_pipelineModel = use_clf_pipeline.fit(trainDataset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.56 s, sys: 463 ms, total: 5.03 s\n",
            "Wall time: 15min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Ns2vU6afKB"
      },
      "source": [
        "###Check the logs\n",
        "We check the logs in order to check on the epochs and the change in loss and accuracy over time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqVc_SUhUTHp",
        "outputId": "b0b06f8a-552a-4a8b-d3bf-c023c04192c1"
      },
      "source": [
        "import os\n",
        "log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n",
        "\n",
        "with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n",
        "    print(log_file.read())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started - epochs: 50 - learning_rate: 0.005 - batch_size: 8 - training_examples: 11899 - classes: 6\n",
            "Epoch 0/50 - 12.70s - loss: 2261.5657 - acc: 0.50877047 - batches: 1488\n",
            "Epoch 1/50 - 10.81s - loss: 2187.4683 - acc: 0.5576384 - batches: 1488\n",
            "Epoch 2/50 - 10.58s - loss: 2109.1465 - acc: 0.61908764 - batches: 1488\n",
            "Epoch 3/50 - 10.79s - loss: 2074.6091 - acc: 0.64175636 - batches: 1488\n",
            "Epoch 4/50 - 10.45s - loss: 2055.1348 - acc: 0.6570556 - batches: 1488\n",
            "Epoch 5/50 - 10.52s - loss: 2039.4285 - acc: 0.66773146 - batches: 1488\n",
            "Epoch 6/50 - 10.51s - loss: 2026.2279 - acc: 0.6763058 - batches: 1488\n",
            "Epoch 7/50 - 10.61s - loss: 2015.6533 - acc: 0.68471193 - batches: 1488\n",
            "Epoch 8/50 - 10.77s - loss: 2007.2582 - acc: 0.6905122 - batches: 1488\n",
            "Epoch 9/50 - 10.47s - loss: 2001.5853 - acc: 0.69521964 - batches: 1488\n",
            "Epoch 10/50 - 10.47s - loss: 1996.3895 - acc: 0.699759 - batches: 1488\n",
            "Epoch 11/50 - 10.58s - loss: 1990.5846 - acc: 0.7034297 - batches: 1488\n",
            "Epoch 12/50 - 10.40s - loss: 1983.8116 - acc: 0.7081372 - batches: 1488\n",
            "Epoch 13/50 - 10.54s - loss: 1978.2646 - acc: 0.7112475 - batches: 1488\n",
            "Epoch 14/50 - 10.54s - loss: 1973.3992 - acc: 0.714694 - batches: 1488\n",
            "Epoch 15/50 - 10.65s - loss: 1970.1115 - acc: 0.717384 - batches: 1488\n",
            "Epoch 16/50 - 10.55s - loss: 1967.1125 - acc: 0.7197377 - batches: 1488\n",
            "Epoch 17/50 - 10.46s - loss: 1963.013 - acc: 0.72158706 - batches: 1488\n",
            "Epoch 18/50 - 10.71s - loss: 1960.4545 - acc: 0.7226799 - batches: 1488\n",
            "Epoch 19/50 - 10.48s - loss: 1959.2318 - acc: 0.7242771 - batches: 1488\n",
            "Epoch 20/50 - 10.54s - loss: 1957.5304 - acc: 0.7259583 - batches: 1488\n",
            "Epoch 21/50 - 10.61s - loss: 1955.6127 - acc: 0.72671485 - batches: 1488\n",
            "Epoch 22/50 - 10.88s - loss: 1952.6661 - acc: 0.72780764 - batches: 1488\n",
            "Epoch 23/50 - 10.43s - loss: 1951.384 - acc: 0.72932076 - batches: 1488\n",
            "Epoch 24/50 - 10.58s - loss: 1949.9999 - acc: 0.7311701 - batches: 1488\n",
            "Epoch 25/50 - 10.46s - loss: 1948.3806 - acc: 0.7320108 - batches: 1488\n",
            "Epoch 26/50 - 10.44s - loss: 1946.3369 - acc: 0.73301953 - batches: 1488\n",
            "Epoch 27/50 - 10.69s - loss: 1943.9559 - acc: 0.7342804 - batches: 1488\n",
            "Epoch 28/50 - 10.61s - loss: 1941.6998 - acc: 0.7348689 - batches: 1488\n",
            "Epoch 29/50 - 10.50s - loss: 1940.5278 - acc: 0.7354573 - batches: 1488\n",
            "Epoch 30/50 - 10.58s - loss: 1939.6935 - acc: 0.73638195 - batches: 1488\n",
            "Epoch 31/50 - 10.44s - loss: 1939.0889 - acc: 0.7372226 - batches: 1488\n",
            "Epoch 32/50 - 10.47s - loss: 1938.1201 - acc: 0.7378951 - batches: 1488\n",
            "Epoch 33/50 - 10.76s - loss: 1937.6963 - acc: 0.73814726 - batches: 1488\n",
            "Epoch 34/50 - 10.46s - loss: 1936.832 - acc: 0.73873574 - batches: 1488\n",
            "Epoch 35/50 - 10.55s - loss: 1936.4662 - acc: 0.739156 - batches: 1488\n",
            "Epoch 36/50 - 10.47s - loss: 1935.9618 - acc: 0.7397444 - batches: 1488\n",
            "Epoch 37/50 - 10.52s - loss: 1934.6848 - acc: 0.7403329 - batches: 1488\n",
            "Epoch 38/50 - 10.47s - loss: 1933.1548 - acc: 0.7409213 - batches: 1488\n",
            "Epoch 39/50 - 10.56s - loss: 1931.5875 - acc: 0.7414257 - batches: 1488\n",
            "Epoch 40/50 - 10.46s - loss: 1930.7448 - acc: 0.74159384 - batches: 1488\n",
            "Epoch 41/50 - 10.50s - loss: 1930.0693 - acc: 0.7422663 - batches: 1488\n",
            "Epoch 42/50 - 10.40s - loss: 1929.3983 - acc: 0.7426025 - batches: 1488\n",
            "Epoch 43/50 - 10.36s - loss: 1928.9425 - acc: 0.7428547 - batches: 1488\n",
            "Epoch 44/50 - 10.54s - loss: 1927.8876 - acc: 0.74327505 - batches: 1488\n",
            "Epoch 45/50 - 10.50s - loss: 1926.8376 - acc: 0.7433591 - batches: 1488\n",
            "Epoch 46/50 - 10.78s - loss: 1925.9498 - acc: 0.74411565 - batches: 1488\n",
            "Epoch 47/50 - 10.60s - loss: 1925.023 - acc: 0.7442838 - batches: 1488\n",
            "Epoch 48/50 - 10.57s - loss: 1924.8486 - acc: 0.744536 - batches: 1488\n",
            "Epoch 49/50 - 10.54s - loss: 1924.531 - acc: 0.74462 - batches: 1488\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKiKZYTVamMI"
      },
      "source": [
        "##Evaluate model\n",
        "###Predict using test dataset\n",
        "Here we take our test dataset and collect the predicted output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz6QhOEuUU4X",
        "outputId": "851e258e-3713-4fbf-cbb5-9b14eeb12755"
      },
      "source": [
        "preds = clf_pipelineModel.transform(testDataset)\n",
        "preds.select('category','description','class.result').show(n=5, truncate=50)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------+---------+\n",
            "|category|                                       description|   result|\n",
            "+--------+--------------------------------------------------+---------+\n",
            "|     Joy|i have immense sympathy with the general point ...|    [Joy]|\n",
            "|     Joy|   i do not feel reassured anxiety is on each side|   [Fear]|\n",
            "| Sadness|              i didnt really feel that embarrassed|[Sadness]|\n",
            "|   Anger|i already feel like i fucked up though because ...|[Sadness]|\n",
            "| Sadness|i feel so inhibited in someone elses kitchen li...|    [Joy]|\n",
            "+--------+--------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaZ05ng_atDW"
      },
      "source": [
        "###Get model metrics\n",
        "Then we take the predictions and use evaluative metrics from sklearn to see how well the model did across different model performance statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqBatffUVDOE",
        "outputId": "7d22ff50-b9f8-4649-a38f-8559fef4aaf1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "preds_df = preds.select('category','description','class.result').toPandas()\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
        "print(classification_report(preds_df['result'], preds_df['category']))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Anger       0.54      0.56      0.55       510\n",
            "        Fear       0.49      0.58      0.53       426\n",
            "         Joy       0.83      0.64      0.72      1796\n",
            "        Love       0.00      0.00      0.00         0\n",
            "     Sadness       0.72      0.64      0.68      1369\n",
            "    Surprise       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.62      4101\n",
            "   macro avg       0.43      0.40      0.41      4101\n",
            "weighted avg       0.72      0.62      0.67      4101\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82smZ2OJZ1Dz"
      },
      "source": [
        "We can repeat for the training dataset to see how well the original dataset performed to assess for possible overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-_FPLSmZ0Mu",
        "outputId": "c5a5dcba-93ff-4c96-93fa-737e3685d136"
      },
      "source": [
        "preds = clf_pipelineModel.transform(trainDataset)\n",
        "preds_df = preds.select('category','description','class.result').toPandas()\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
        "print(classification_report(preds_df['result'], preds_df['category']))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Anger       0.73      0.78      0.76      1522\n",
            "        Fear       0.72      0.81      0.77      1276\n",
            "         Joy       0.90      0.71      0.79      5083\n",
            "        Love       0.00      0.00      0.00         0\n",
            "     Sadness       0.88      0.76      0.81      4018\n",
            "    Surprise       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.74     11899\n",
            "   macro avg       0.54      0.51      0.52     11899\n",
            "weighted avg       0.85      0.74      0.79     11899\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzlY9ApFrX4r"
      },
      "source": [
        "###Predict a random example\n",
        "Here we transform the pipeline into a light-weight version and use a plausibly confusing sentence ('not happy') to see if the model can figure out the true tone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWrYBTojlemD",
        "outputId": "c9c9aad7-77b7-4fc9-deea-24794956b41c"
      },
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "light_model = LightPipeline(clf_pipelineModel)\n",
        "text = 'i am not happy'\n",
        "light_model.annotate(text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class': ['Joy'],\n",
              " 'document': ['i am not happy'],\n",
              " 'sentence_embeddings': ['i am not happy']}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6zO1wCc9dtO"
      },
      "source": [
        "##Save the pipeline\n",
        "###Save the directory and convert to TAR archive\n",
        "We will want to import the pipeline later so we save the model and compress it to make it easier for transport."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UON9m8H9wJr",
        "outputId": "96ae9b72-b7c2-4f7a-f5c3-e8f61ee28f70"
      },
      "source": [
        "clf_pipelineModel.write().save('ToneItPipeline')\n",
        "!tar czvf ToneItPipeline.tar.gz ToneItPipeline"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ToneItPipeline/\n",
            "ToneItPipeline/stages/\n",
            "ToneItPipeline/stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/\n",
            "ToneItPipeline/stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/.use_tensorflow.crc\n",
            "ToneItPipeline/stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/\n",
            "ToneItPipeline/stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/._SUCCESS.crc\n",
            "ToneItPipeline/stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/part-00000\n",
            "ToneItPipeline/stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/_SUCCESS\n",
            "ToneItPipeline/stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/.part-00000.crc\n",
            "ToneItPipeline/stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/use_tensorflow\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/.classifierdl_tensorflow.crc\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/fields/\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/fields/datasetParams/\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/fields/datasetParams/._SUCCESS.crc\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/fields/datasetParams/part-00000\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/fields/datasetParams/part-00001\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/fields/datasetParams/.part-00001.crc\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/fields/datasetParams/_SUCCESS\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/fields/datasetParams/.part-00000.crc\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/metadata/\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/metadata/._SUCCESS.crc\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/metadata/part-00000\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/metadata/_SUCCESS\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/metadata/.part-00000.crc\n",
            "ToneItPipeline/stages/2_ClassifierDLModel_b2de7b745e33/classifierdl_tensorflow\n",
            "ToneItPipeline/stages/0_DocumentAssembler_b2fa098e1cf7/\n",
            "ToneItPipeline/stages/0_DocumentAssembler_b2fa098e1cf7/metadata/\n",
            "ToneItPipeline/stages/0_DocumentAssembler_b2fa098e1cf7/metadata/._SUCCESS.crc\n",
            "ToneItPipeline/stages/0_DocumentAssembler_b2fa098e1cf7/metadata/part-00000\n",
            "ToneItPipeline/stages/0_DocumentAssembler_b2fa098e1cf7/metadata/_SUCCESS\n",
            "ToneItPipeline/stages/0_DocumentAssembler_b2fa098e1cf7/metadata/.part-00000.crc\n",
            "ToneItPipeline/metadata/\n",
            "ToneItPipeline/metadata/._SUCCESS.crc\n",
            "ToneItPipeline/metadata/part-00000\n",
            "ToneItPipeline/metadata/_SUCCESS\n",
            "ToneItPipeline/metadata/.part-00000.crc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkJzTsa5_IoN"
      },
      "source": [
        "###Check on the size\n",
        "We note that the compression did not significantly reduce the size however it still saves us some space and files are easier to transport than directories (which usually require compression to archives anyway)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcLBk7ko_AMf",
        "outputId": "d35a5ed0-49a3-4a5d-89e3-3caa31347de9"
      },
      "source": [
        "# size of the raw directory\n",
        "!du -sch ToneItPipeline"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "872M\tToneItPipeline\n",
            "872M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEt4oBxjCxKg",
        "outputId": "f8b3e4ef-0af1-4d48-96da-416958b78f98"
      },
      "source": [
        "# size of the compressed archive\n",
        "!du -sch ToneItPipeline.tar.gz"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "775M\tToneItPipeline.tar.gz\n",
            "775M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwN-2jGj-jyy"
      },
      "source": [
        "###Load the pipeline\n",
        "Now we can take our saved pipeline and load it to see if we can effectively annotate random lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_in3IuQAHZ2",
        "outputId": "8703f0f2-56c6-4d40-95b6-48bf013084c6"
      },
      "source": [
        "%%time\n",
        "import sparknlp\n",
        "sparknlp.start()\n",
        "from pyspark.ml import PipelineModel\n",
        "from sparknlp.base import LightPipeline\n",
        "ToneItPipeline = LightPipeline(PipelineModel.load('ToneItPipeline'))\n",
        "ToneItPipeline.annotate(\"we fell to the floor our faces pale\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 203 ms, sys: 33.6 ms, total: 237 ms\n",
            "Wall time: 33.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKaVCi5ws2th"
      },
      "source": [
        "universalsentenceencoder --> 0.69<br>\n",
        "tokenizer+bertsmall+sentence --> 0.29!!!ALLSAD<br>\n",
        "bertsmallsent --> 0.35!!!ALLJOY<br>\n",
        "bertusecmlmenbase --> 0.35!!!ALLJOY"
      ]
    }
  ]
}